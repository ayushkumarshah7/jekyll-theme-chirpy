{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFkYYgclCGMd"
   },
   "source": [
    "![messy-notebook](/assets/img/messy_nb.png)\n",
    "\n",
    "Does it ring a bell looking at this messy notebook? I am sure you must have created or encountered a similar kind of notebook while performing data analysis tasks in pandas. \n",
    "\n",
    "Pandas is widely used by data scientists and ML Engineers all around the world to perform all kinds of data related tasks like data cleaning and prerprocessing, data anlysis, data manipulation, data conversion, etc. However, most of us are not using it right, as seen in the above example, which has decreased our productivity a lot.\n",
    "\n",
    "You might wonder then what is the correct way to use pandas. Is there any particular way that we can make the notebook clean and modular so that we can increase our productivity? \n",
    "\n",
    "Luckily, there is a type of quick hack or technique, whatever you may call it, which can be used to greatly improve the workflow and make notebooks not only clean and well organized but highly productive and efficient. The good thing is that you don't need to install any extra packages or libraries. At the end, your notebook will look something like this.\n",
    "\n",
    "![Clean notebook](/assets/img/clean_nb.png)\n",
    "\n",
    "> Note: Dark mode is available in this website. You can switch between the modes by clicking the leftmost button at the bottom of the left sidebar.\n",
    "\n",
    "  ![dark_mode](/assets/img/dark_mode.png)\n",
    "\n",
    "# Untitled12.ipynb\n",
    "\n",
    "The way to achieve clean and well organized pandas notebooks was explored in the presentation [Untitled12.ipynb](https://pydata.org/eindhoven2019/schedule/presentation/19/untitled12ipynb/) by [Vincent D. Warmerdam](https://twitter.com/fishnets88?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor) at [PyData Eindhoven 2019](https://pydata.org/eindhoven2019/)\n",
    "\n",
    "The presentation [Untitled12.ipynb: Prevent Miles of Scrolling, Reduce the Spaghetti Code from the Copy Pasta](https://www.youtube.com/watch?v=MpFZUshKypk&t=1292s) has been uploaded in youtube as well. You can watch the video below if you want:\n",
    "\n",
    "{% include iframe_holder.html url=\"https://www.youtube.com/embed/MpFZUshKypk\" width=\"560\" height=\"315\" %}\n",
    "\n",
    "In this article, I will briefly summarize the presenation by [Vincent D. Warmerdam](https://twitter.com/fishnets88?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor) and then move on to the code implementation (solution) and a few code examples based on the methods used in his presentation.\n",
    "\n",
    "**The Untitled phenomena**\n",
    "\n",
    "![Untitled12.ipynb](/assets/img/Untitled12.png)\n",
    "\n",
    "He began his talk by introducing a term called **`Untitled phenomena`**. The term simple refers to the bad practice of not naming the notebook files which eventually creates an unorganized bunch of Untitled notebooks. As a result, he also named the presentation **`Untitled12.ipynb`**. \n",
    "\n",
    "Moreover, not only the bad practice of naming that we follow, but also the bad organization of code inside the notebook needs to be improved. Copying and pasting code multiple times creates spaghetti code. This is especially true for a lot of data science based Jupyter notebooks. The goal of his talk was to uncover a great pattern for pandas that would prevent loads of scrolling such that the code behaves like lego. He also gave some useful tricks and tips on how to prevent miles of scrolling and reduce the spaghetti code when creating Jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxRNH5PY56f0"
   },
   "source": [
    "## **>> [Skip to coding solution](#solution)**\n",
    "\n",
    "I have intially written a brief summary of the talk Untitled12.ipynb and explored some sommon problems in the usual coding style before moving to the solution. If you want to directly jump to the coding solution to create clean pandas notebook using pipeline, then click the link above. However, I recommend you to read the common problems I have mentioned before going to the solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1KmZml3VQ-S"
   },
   "source": [
    "\n",
    "# Contents\n",
    "\n",
    "I will be talking about the following topics which will more or less revolve around his talk.\n",
    "\n",
    "- [Importance of Workflow](#importance)\n",
    "- [The Usual coding style](#current)\n",
    "- [Problems in the usual coding style](#problems)\n",
    "- [Coding Solution](#solution)\n",
    "- [Advantages](#advantages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_oXRUaOVTu3"
   },
   "source": [
    "\n",
    "<a name=\"importance\"></a>\n",
    "\n",
    "## Importance of Workflow\n",
    "\n",
    "At the beginning of the presentaion, he began by discussing the following points that highlights the importance of workflows and the need of jupyter-notebook and pandas over excel:\n",
    "\n",
    "- We want to separate the data from the analysis: Tha analysis portion should not modify the raw data. The raw data should be safe from these modifications so that it can be reused later as well. However, this is not possible in excel.\n",
    "\n",
    "- We want to be able to automate our analysis. The main aim of programming and workflow is automation. Our tasks become a lot easier if we are able to automate the anlayis using a pandas script rather than performing the analysis every time using Excel.\n",
    "\n",
    "- We want our analysis to be reproducible i.e. we must be able to reproduce the same analysis results on the data at a later time in the future.\n",
    "\n",
    "- We should not pay a third part obscene amounts of money for something as basic as arithmetic. This budget is better allocated towards innovation and education of staff.\n",
    "\n",
    "However, the current style of coding in pandas and jupyter notebook has solved only the last point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J5beTPzTVVoI"
   },
   "source": [
    "\n",
    "<a name=\"current\"></a>\n",
    "\n",
    "## The usual coding style\n",
    "\n",
    "Let's explore the common practice of writing pandas code and try to point out the major problems in such approaches.\n",
    "\n",
    "Intially, I will show the general workflow that most of us follow while using pandas. I will be performing some analysis on the real COVID 19 dataset of the U.S. states obtained from\n",
    "[The COVID Tracking Project](https://covidtracking.com/) which is avilable under the [Creative Commons CC BY-NC-4.0 license](https://creativecommons.org/licenses/by-nc/4.0/). The dataset is updated each day between 4pm and 5pm EDT.\n",
    "\n",
    "After showing the common approach, I will point out the major pitfalls and then move on to the solution.\n",
    "\n",
    "First, I will download the U.S. COVID-19 dataset using the API provided by [The COVID Tracking Project](https://covidtracking.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "szRdFaArcUP0",
    "outputId": "fc455a52-5e5b-42e1-d74f-df9bc16d388b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-05 16:34:10--  https://covidtracking.com/api/v1/states/daily.csv\n",
      "Resolving covidtracking.com (covidtracking.com)... 104.248.63.231, 2604:a880:400:d1::888:7001\n",
      "Connecting to covidtracking.com (covidtracking.com)|104.248.63.231|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘data/covid19_us_states_daily.csv’\n",
      "\n",
      "\r",
      "          data/covi     [<=>                 ]       0  --.-KB/s               \r",
      "         data/covid     [ <=>                ] 598.95K  2.79MB/s               \r",
      "data/covid19_us_sta     [  <=>               ] 987.40K  3.11MB/s    in 0.3s    \n",
      "\n",
      "2020-06-05 16:34:11 (3.11 MB/s) - ‘data/covid19_us_states_daily.csv’ saved [1011093]\n",
      "\n",
      "--2020-06-05 16:34:12--  https://covidtracking.com/api/v1/states/info.csv\n",
      "Resolving covidtracking.com (covidtracking.com)... 104.248.50.87, 2604:a880:400:d1::888:7001\n",
      "Connecting to covidtracking.com (covidtracking.com)|104.248.50.87|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘data/state_info.csv’\n",
      "\n",
      "data/state_info.csv     [ <=>                ]  27.67K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2020-06-05 16:34:13 (1.43 MB/s) - ‘data/state_info.csv’ saved [28329]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!wget -O data/covid19_us_states_daily.csv https://covidtracking.com/api/v1/states/daily.csv\n",
    "!wget  -O data/state_info.csv https://covidtracking.com/api/v1/states/info.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8USnXAyU-8k"
   },
   "outputs": [],
   "source": [
    "import numpy as mp\n",
    "import pandas as pd \n",
    "# Importing plotly library for plotting interactive graphs\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "idUwN7AcVtnU"
   },
   "source": [
    "The first step is generally to read or import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "_RJrcNhEI3f3",
    "outputId": "20395212-235f-41aa-f6fe-fa66a5f7e3ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>pending</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "      <th>hospitalizedCumulative</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "      <th>inIcuCumulative</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "      <th>onVentilatorCumulative</th>\n",
       "      <th>recovered</th>\n",
       "      <th>dataQualityGrade</th>\n",
       "      <th>lastUpdateEt</th>\n",
       "      <th>dateModified</th>\n",
       "      <th>checkTimeEt</th>\n",
       "      <th>death</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>dateChecked</th>\n",
       "      <th>fips</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>posNeg</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>hash</th>\n",
       "      <th>commercialScore</th>\n",
       "      <th>negativeRegularScore</th>\n",
       "      <th>negativeScore</th>\n",
       "      <th>positiveScore</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20200604</th>\n",
       "      <td>AK</td>\n",
       "      <td>513.0</td>\n",
       "      <td>59584.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>376.0</td>\n",
       "      <td>A</td>\n",
       "      <td>6/4/2020 00:00</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>06/03 20:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1907</td>\n",
       "      <td>60097</td>\n",
       "      <td>60097</td>\n",
       "      <td>1915</td>\n",
       "      <td>60097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c1046011af7271cbe2e6698526714c6cb5b92748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200604</th>\n",
       "      <td>AL</td>\n",
       "      <td>19072.0</td>\n",
       "      <td>216227.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>601.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.0</td>\n",
       "      <td>11395.0</td>\n",
       "      <td>B</td>\n",
       "      <td>6/4/2020 00:00</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>06/03 20:00</td>\n",
       "      <td>653.0</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>3484</td>\n",
       "      <td>235299</td>\n",
       "      <td>235299</td>\n",
       "      <td>3705</td>\n",
       "      <td>235299</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>bcbefdb36212ba2b97b5a354f4e45bf16648ee23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200604</th>\n",
       "      <td>AR</td>\n",
       "      <td>8067.0</td>\n",
       "      <td>134413.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>5717.0</td>\n",
       "      <td>A</td>\n",
       "      <td>6/4/2020 00:00</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>06/03 20:00</td>\n",
       "      <td>142.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142480</td>\n",
       "      <td>142480</td>\n",
       "      <td>0</td>\n",
       "      <td>142480</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>acd3a4fbbc3dbb32138725f91e3261d683e7052a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200604</th>\n",
       "      <td>AS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>6/1/2020 00:00</td>\n",
       "      <td>2020-06-01T00:00:00Z</td>\n",
       "      <td>05/31 20:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-01T00:00:00Z</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8bbc72fa42781e0549e2e4f9f4c3e7cbef14ab32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200604</th>\n",
       "      <td>AZ</td>\n",
       "      <td>22753.0</td>\n",
       "      <td>227002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5172.0</td>\n",
       "      <td>A+</td>\n",
       "      <td>6/4/2020 00:00</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>06/03 20:00</td>\n",
       "      <td>996.0</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>4</td>\n",
       "      <td>520</td>\n",
       "      <td>4710</td>\n",
       "      <td>249755</td>\n",
       "      <td>249755</td>\n",
       "      <td>5230</td>\n",
       "      <td>249755</td>\n",
       "      <td>15</td>\n",
       "      <td>66</td>\n",
       "      <td>1fa237b8204cd23701577aef6338d339daa4452e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         state  positive  negative  ...  positiveScore  score  grade\n",
       "date                                ...                             \n",
       "20200604    AK     513.0   59584.0  ...              0      0    NaN\n",
       "20200604    AL   19072.0  216227.0  ...              0      0    NaN\n",
       "20200604    AR    8067.0  134413.0  ...              0      0    NaN\n",
       "20200604    AS       0.0     174.0  ...              0      0    NaN\n",
       "20200604    AZ   22753.0  227002.0  ...              0      0    NaN\n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/covid19_us_states_daily.csv', index_col='date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TSkNl6y1WtPh"
   },
   "source": [
    "After taking a glance at the data, I realize that the date is not formatted well, so I format it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "rex60D7rPuqT",
    "outputId": "6a46e206-7bce-4e13-92b8-cc7fe728c26e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>pending</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "      <th>hospitalizedCumulative</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "      <th>inIcuCumulative</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "      <th>onVentilatorCumulative</th>\n",
       "      <th>recovered</th>\n",
       "      <th>dataQualityGrade</th>\n",
       "      <th>lastUpdateEt</th>\n",
       "      <th>dateModified</th>\n",
       "      <th>checkTimeEt</th>\n",
       "      <th>death</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>dateChecked</th>\n",
       "      <th>fips</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>posNeg</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>hash</th>\n",
       "      <th>commercialScore</th>\n",
       "      <th>negativeRegularScore</th>\n",
       "      <th>negativeScore</th>\n",
       "      <th>positiveScore</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AK</td>\n",
       "      <td>513.0</td>\n",
       "      <td>59584.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>376.0</td>\n",
       "      <td>A</td>\n",
       "      <td>6/4/2020 00:00</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>06/03 20:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1907</td>\n",
       "      <td>60097</td>\n",
       "      <td>60097</td>\n",
       "      <td>1915</td>\n",
       "      <td>60097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c1046011af7271cbe2e6698526714c6cb5b92748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AL</td>\n",
       "      <td>19072.0</td>\n",
       "      <td>216227.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>601.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.0</td>\n",
       "      <td>11395.0</td>\n",
       "      <td>B</td>\n",
       "      <td>6/4/2020 00:00</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>06/03 20:00</td>\n",
       "      <td>653.0</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>3484</td>\n",
       "      <td>235299</td>\n",
       "      <td>235299</td>\n",
       "      <td>3705</td>\n",
       "      <td>235299</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>bcbefdb36212ba2b97b5a354f4e45bf16648ee23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AR</td>\n",
       "      <td>8067.0</td>\n",
       "      <td>134413.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>5717.0</td>\n",
       "      <td>A</td>\n",
       "      <td>6/4/2020 00:00</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>06/03 20:00</td>\n",
       "      <td>142.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142480</td>\n",
       "      <td>142480</td>\n",
       "      <td>0</td>\n",
       "      <td>142480</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>acd3a4fbbc3dbb32138725f91e3261d683e7052a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>6/1/2020 00:00</td>\n",
       "      <td>2020-06-01T00:00:00Z</td>\n",
       "      <td>05/31 20:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-01T00:00:00Z</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8bbc72fa42781e0549e2e4f9f4c3e7cbef14ab32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AZ</td>\n",
       "      <td>22753.0</td>\n",
       "      <td>227002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5172.0</td>\n",
       "      <td>A+</td>\n",
       "      <td>6/4/2020 00:00</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>06/03 20:00</td>\n",
       "      <td>996.0</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>4</td>\n",
       "      <td>520</td>\n",
       "      <td>4710</td>\n",
       "      <td>249755</td>\n",
       "      <td>249755</td>\n",
       "      <td>5230</td>\n",
       "      <td>249755</td>\n",
       "      <td>15</td>\n",
       "      <td>66</td>\n",
       "      <td>1fa237b8204cd23701577aef6338d339daa4452e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           state  positive  negative  ...  positiveScore  score  grade\n",
       "date                                  ...                             \n",
       "2020-06-04    AK     513.0   59584.0  ...              0      0    NaN\n",
       "2020-06-04    AL   19072.0  216227.0  ...              0      0    NaN\n",
       "2020-06-04    AR    8067.0  134413.0  ...              0      0    NaN\n",
       "2020-06-04    AS       0.0     174.0  ...              0      0    NaN\n",
       "2020-06-04    AZ   22753.0  227002.0  ...              0      0    NaN\n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index = pd.to_datetime(df.index, format=\"%Y%m%d\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tBNW8_ARWGuM"
   },
   "source": [
    "Then, I try to view some additional information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "-kWAPCRxa0HQ",
    "outputId": "e2e84ea5-d6ad-46fb-d4f5-bb7ebd33537d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5113 entries, 2020-06-04 to 2020-01-22\n",
      "Data columns (total 34 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   state                     5113 non-null   object \n",
      " 1   positive                  5098 non-null   float64\n",
      " 2   negative                  4902 non-null   float64\n",
      " 3   pending                   842 non-null    float64\n",
      " 4   hospitalizedCurrently     2591 non-null   float64\n",
      " 5   hospitalizedCumulative    2318 non-null   float64\n",
      " 6   inIcuCurrently            1362 non-null   float64\n",
      " 7   inIcuCumulative           576 non-null    float64\n",
      " 8   onVentilatorCurrently     1157 non-null   float64\n",
      " 9   onVentilatorCumulative    198 non-null    float64\n",
      " 10  recovered                 2409 non-null   float64\n",
      " 11  dataQualityGrade          4012 non-null   object \n",
      " 12  lastUpdateEt              4758 non-null   object \n",
      " 13  dateModified              4758 non-null   object \n",
      " 14  checkTimeEt               4758 non-null   object \n",
      " 15  death                     4388 non-null   float64\n",
      " 16  hospitalized              2318 non-null   float64\n",
      " 17  dateChecked               4758 non-null   object \n",
      " 18  fips                      5113 non-null   int64  \n",
      " 19  positiveIncrease          5113 non-null   int64  \n",
      " 20  negativeIncrease          5113 non-null   int64  \n",
      " 21  total                     5113 non-null   int64  \n",
      " 22  totalTestResults          5113 non-null   int64  \n",
      " 23  totalTestResultsIncrease  5113 non-null   int64  \n",
      " 24  posNeg                    5113 non-null   int64  \n",
      " 25  deathIncrease             5113 non-null   int64  \n",
      " 26  hospitalizedIncrease      5113 non-null   int64  \n",
      " 27  hash                      5113 non-null   object \n",
      " 28  commercialScore           5113 non-null   int64  \n",
      " 29  negativeRegularScore      5113 non-null   int64  \n",
      " 30  negativeScore             5113 non-null   int64  \n",
      " 31  positiveScore             5113 non-null   int64  \n",
      " 32  score                     5113 non-null   int64  \n",
      " 33  grade                     0 non-null      float64\n",
      "dtypes: float64(13), int64(14), object(7)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfQISaBTbC1N"
   },
   "source": [
    "You can see that there are various columns that are not of use. So, I decide to remove such columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "RL5YpqbKbTCR",
    "outputId": "27096497-4aa4-48b3-93b4-35a92c29a03f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5113 entries, 2020-06-04 to 2020-01-22\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   state                     5113 non-null   object \n",
      " 1   positive                  5098 non-null   float64\n",
      " 2   negative                  4902 non-null   float64\n",
      " 3   pending                   842 non-null    float64\n",
      " 4   recovered                 2409 non-null   float64\n",
      " 5   death                     4388 non-null   float64\n",
      " 6   hospitalized              2318 non-null   float64\n",
      " 7   dateChecked               4758 non-null   object \n",
      " 8   positiveIncrease          5113 non-null   int64  \n",
      " 9   negativeIncrease          5113 non-null   int64  \n",
      " 10  total                     5113 non-null   int64  \n",
      " 11  totalTestResults          5113 non-null   int64  \n",
      " 12  totalTestResultsIncrease  5113 non-null   int64  \n",
      " 13  deathIncrease             5113 non-null   int64  \n",
      " 14  hospitalizedIncrease      5113 non-null   int64  \n",
      " 15  hash                      5113 non-null   object \n",
      " 16  commercialScore           5113 non-null   int64  \n",
      " 17  negativeRegularScore      5113 non-null   int64  \n",
      " 18  negativeScore             5113 non-null   int64  \n",
      " 19  positiveScore             5113 non-null   int64  \n",
      " 20  score                     5113 non-null   int64  \n",
      " 21  grade                     0 non-null      float64\n",
      "dtypes: float64(7), int64(12), object(3)\n",
      "memory usage: 918.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.drop([*df.columns[4:10], *df.columns[11:15], 'posNeg', 'fips'], \n",
    "        axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wQx9eus4mDV6"
   },
   "source": [
    "I also realize that there are a lot of missing (nan or null) values. So, I replace the missing values by 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "1VoGhBaik23K",
    "outputId": "7b4422cd-63b9-4a79-d4ad-92e24be9876a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>pending</th>\n",
       "      <th>recovered</th>\n",
       "      <th>death</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>dateChecked</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>hash</th>\n",
       "      <th>commercialScore</th>\n",
       "      <th>negativeRegularScore</th>\n",
       "      <th>negativeScore</th>\n",
       "      <th>positiveScore</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AK</td>\n",
       "      <td>513.0</td>\n",
       "      <td>59584.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>8</td>\n",
       "      <td>1907</td>\n",
       "      <td>60097</td>\n",
       "      <td>60097</td>\n",
       "      <td>1915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c1046011af7271cbe2e6698526714c6cb5b92748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AL</td>\n",
       "      <td>19072.0</td>\n",
       "      <td>216227.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11395.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>221</td>\n",
       "      <td>3484</td>\n",
       "      <td>235299</td>\n",
       "      <td>235299</td>\n",
       "      <td>3705</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>bcbefdb36212ba2b97b5a354f4e45bf16648ee23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AR</td>\n",
       "      <td>8067.0</td>\n",
       "      <td>134413.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5717.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142480</td>\n",
       "      <td>142480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>acd3a4fbbc3dbb32138725f91e3261d683e7052a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-06-01T00:00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8bbc72fa42781e0549e2e4f9f4c3e7cbef14ab32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AZ</td>\n",
       "      <td>22753.0</td>\n",
       "      <td>227002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5172.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>520</td>\n",
       "      <td>4710</td>\n",
       "      <td>249755</td>\n",
       "      <td>249755</td>\n",
       "      <td>5230</td>\n",
       "      <td>15</td>\n",
       "      <td>66</td>\n",
       "      <td>1fa237b8204cd23701577aef6338d339daa4452e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           state  positive  negative  ...  positiveScore  score  grade\n",
       "date                                  ...                             \n",
       "2020-06-04    AK     513.0   59584.0  ...              0      0    0.0\n",
       "2020-06-04    AL   19072.0  216227.0  ...              0      0    0.0\n",
       "2020-06-04    AR    8067.0  134413.0  ...              0      0    0.0\n",
       "2020-06-04    AS       0.0     174.0  ...              0      0    0.0\n",
       "2020-06-04    AZ   22753.0  227002.0  ...              0      0    0.0\n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(value=0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uFyqUWSQCkEm"
   },
   "source": [
    "I also want to add a column corresponding to state name instead of the abbreviation. So, I merge state_info with the current dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "xF_FNPvX9gku",
    "outputId": "7ff76cba-93ab-438e-9955-2a096eeb30a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>pending</th>\n",
       "      <th>recovered</th>\n",
       "      <th>death</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>dateChecked</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>hash</th>\n",
       "      <th>commercialScore</th>\n",
       "      <th>negativeRegularScore</th>\n",
       "      <th>negativeScore</th>\n",
       "      <th>positiveScore</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>AK</td>\n",
       "      <td>513.0</td>\n",
       "      <td>59584.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>8</td>\n",
       "      <td>1907</td>\n",
       "      <td>60097</td>\n",
       "      <td>60097</td>\n",
       "      <td>1915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c1046011af7271cbe2e6698526714c6cb5b92748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>AL</td>\n",
       "      <td>19072.0</td>\n",
       "      <td>216227.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11395.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>221</td>\n",
       "      <td>3484</td>\n",
       "      <td>235299</td>\n",
       "      <td>235299</td>\n",
       "      <td>3705</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>bcbefdb36212ba2b97b5a354f4e45bf16648ee23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>AR</td>\n",
       "      <td>8067.0</td>\n",
       "      <td>134413.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5717.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142480</td>\n",
       "      <td>142480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>acd3a4fbbc3dbb32138725f91e3261d683e7052a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>AS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-06-01T00:00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8bbc72fa42781e0549e2e4f9f4c3e7cbef14ab32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>American Samoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>AZ</td>\n",
       "      <td>22753.0</td>\n",
       "      <td>227002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5172.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>520</td>\n",
       "      <td>4710</td>\n",
       "      <td>249755</td>\n",
       "      <td>249755</td>\n",
       "      <td>5230</td>\n",
       "      <td>15</td>\n",
       "      <td>66</td>\n",
       "      <td>1fa237b8204cd23701577aef6338d339daa4452e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date state  positive  ...  score  grade            name\n",
       "0 2020-06-04    AK     513.0  ...      0    0.0          Alaska\n",
       "1 2020-06-04    AL   19072.0  ...      0    0.0         Alabama\n",
       "2 2020-06-04    AR    8067.0  ...      0    0.0        Arkansas\n",
       "3 2020-06-04    AS       0.0  ...      0    0.0  American Samoa\n",
       "4 2020-06-04    AZ   22753.0  ...      0    0.0         Arizona\n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('data/state_info.csv', usecols=['state', 'name'])\n",
    "df3 = (df\n",
    "      .reset_index()\n",
    "      .merge(df2, on='state', how='left', left_index=True))\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHjP4bsjflnI"
   },
   "source": [
    "I realize that the date index is lost. So, I reset the date index. Also, it is better to rename column name as state_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "XPaZIc9FfkRK",
    "outputId": "57065f82-1ddc-4540-f94a-8b7b3df271c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>pending</th>\n",
       "      <th>recovered</th>\n",
       "      <th>death</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>dateChecked</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>hash</th>\n",
       "      <th>commercialScore</th>\n",
       "      <th>negativeRegularScore</th>\n",
       "      <th>negativeScore</th>\n",
       "      <th>positiveScore</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "      <th>state_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AK</td>\n",
       "      <td>513.0</td>\n",
       "      <td>59584.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>8</td>\n",
       "      <td>1907</td>\n",
       "      <td>60097</td>\n",
       "      <td>60097</td>\n",
       "      <td>1915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c1046011af7271cbe2e6698526714c6cb5b92748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AL</td>\n",
       "      <td>19072.0</td>\n",
       "      <td>216227.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11395.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>221</td>\n",
       "      <td>3484</td>\n",
       "      <td>235299</td>\n",
       "      <td>235299</td>\n",
       "      <td>3705</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>bcbefdb36212ba2b97b5a354f4e45bf16648ee23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AR</td>\n",
       "      <td>8067.0</td>\n",
       "      <td>134413.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5717.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142480</td>\n",
       "      <td>142480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>acd3a4fbbc3dbb32138725f91e3261d683e7052a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-06-01T00:00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8bbc72fa42781e0549e2e4f9f4c3e7cbef14ab32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>American Samoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>AZ</td>\n",
       "      <td>22753.0</td>\n",
       "      <td>227002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5172.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>520</td>\n",
       "      <td>4710</td>\n",
       "      <td>249755</td>\n",
       "      <td>249755</td>\n",
       "      <td>5230</td>\n",
       "      <td>15</td>\n",
       "      <td>66</td>\n",
       "      <td>1fa237b8204cd23701577aef6338d339daa4452e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           state  positive  negative  ...  score  grade      state_name\n",
       "date                                  ...                              \n",
       "2020-06-04    AK     513.0   59584.0  ...      0    0.0          Alaska\n",
       "2020-06-04    AL   19072.0  216227.0  ...      0    0.0         Alabama\n",
       "2020-06-04    AR    8067.0  134413.0  ...      0    0.0        Arkansas\n",
       "2020-06-04    AS       0.0     174.0  ...      0    0.0  American Samoa\n",
       "2020-06-04    AZ   22753.0  227002.0  ...      0    0.0         Arizona\n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.set_index('date', inplace=True)\n",
    "df3.rename(columns={'name': 'state_name'}, inplace=True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9s1vFPUrbsAW"
   },
   "source": [
    "Now that the data is ready for some analysis, I decide to plot deaths count in each state indexed by date using the interactive [plotly library](https://plotly.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "azeUZjKcU9SP",
    "outputId": "61ad6afc-acd5-4393-bc94-4a992927dbb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://plotly.com/~ayush.kumar.shah/1/'"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig1 = px.line(df3, x=df3.index, y='death', color='state')\n",
    "fig1.update_layout(xaxis_title='date', title='Total deaths in each state (Cumulative)')\n",
    "py.plot(fig1, filename = 'daily_deaths', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JI-zgv0QgqtH"
   },
   "source": [
    "{% include iframe_holder.html url=\"//plotly.com/~ayush.kumar.shah/1.embed\" width=\"900\" height=\"800\" scrolling=\"no\" %}\n",
    "\n",
    "> Note: These plots are interactive plots, so you can zoom in or out, pinch, hover over the graph, download it, and so on.  \n",
    "\n",
    "Now, I decide to calculalte the total deaths in the US across all states and plot it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "1Jv9XN3WOqp5",
    "outputId": "a240ebda-57cf-4d68-8216-d1ef309fd32e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>pending</th>\n",
       "      <th>recovered</th>\n",
       "      <th>death</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>commercialScore</th>\n",
       "      <th>negativeRegularScore</th>\n",
       "      <th>negativeScore</th>\n",
       "      <th>positiveScore</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive  negative  pending  ...  positiveScore  score  grade\n",
       "date                                     ...                             \n",
       "2020-01-22       1.0       0.0      0.0  ...              0      0    0.0\n",
       "2020-01-23       1.0       0.0      0.0  ...              0      0    0.0\n",
       "2020-01-24       1.0       0.0      0.0  ...              0      0    0.0\n",
       "2020-01-25       1.0       0.0      0.0  ...              0      0    0.0\n",
       "2020-01-26       1.0       0.0      0.0  ...              0      0    0.0\n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = df3.resample('D').sum()\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T2mJ81Vw1jJY",
    "outputId": "6e1a4706-4847-451e-92bb-0775464e8783"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://plotly.com/~ayush.kumar.shah/4/'"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig2 = px.line(df4, x=df4.index, y='death')\n",
    "fig2.update_layout(xaxis_title='date', title='Total deaths in the U.S. (Cumulative)')\n",
    "py.plot(fig2, filename = 'total_daily_deaths', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yIbkVW42pRdM"
   },
   "source": [
    "{% include iframe_holder.html url=\"//plotly.com/~ayush.kumar.shah/4.embed\" width=\"900\" height=\"800\" scrolling=\"no\" %}\n",
    "\n",
    "I also want to calculate the number of Active cases i.e.\n",
    "> Active = positive - deaths - recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fw-jYiu5EP51"
   },
   "outputs": [],
   "source": [
    "df4['active'] = df4['positive'] - df4['death'] - df4['recovered']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IbRgupQj1jJd"
   },
   "source": [
    "Now, after calculating active column, I want to plot active cases instead of death. So, I go to previous cell and replace `death` by `active` and generate the plot.\n",
    "\n",
    "In [25]: df4['~~death~~'].plot()\n",
    "\n",
    "In [25]: df4['active'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2lWdMPLU1jJd",
    "outputId": "f44c7fbf-aae0-41e2-cd60-ee3d658174e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://plotly.com/~ayush.kumar.shah/6/'"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig3 = px.line(df4, x=df4.index, y='active')\n",
    "fig3.update_layout(xaxis_title='date', title='Total active cases in the U.S. (Cumulative)')\n",
    "py.plot(fig3, filename = 'total_daily_active', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwfYAcns1jJg"
   },
   "source": [
    "{% include iframe_holder.html url=\"//plotly.com/~ayush.kumar.shah/6.embed\" width=\"900\" height=\"800\" scrolling=\"no\" %}\n",
    "\n",
    "Then I decide to calculate statistics of a single month May only. Since the data is cumulative, I need to subtract the data of May from data of April to find the increase in various statistics in May after which I plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "rov0DW6vAGrR",
    "outputId": "7f03b8ea-8952-44e8-daa4-74eaf90d51b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>pending</th>\n",
       "      <th>recovered</th>\n",
       "      <th>death</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>10884.0</td>\n",
       "      <td>119473.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9355.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>130357</td>\n",
       "      <td>130357</td>\n",
       "      <td>106</td>\n",
       "      <td>-112</td>\n",
       "      <td>45594</td>\n",
       "      <td>4846</td>\n",
       "      <td>50440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>79.0</td>\n",
       "      <td>32497.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32576</td>\n",
       "      <td>32576</td>\n",
       "      <td>-5</td>\n",
       "      <td>7</td>\n",
       "      <td>17327</td>\n",
       "      <td>-157</td>\n",
       "      <td>17170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Samoa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>12288.0</td>\n",
       "      <td>141132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3262.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>153420</td>\n",
       "      <td>153420</td>\n",
       "      <td>290</td>\n",
       "      <td>660</td>\n",
       "      <td>95076</td>\n",
       "      <td>5929</td>\n",
       "      <td>101005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>3998.0</td>\n",
       "      <td>77138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3970.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>81136</td>\n",
       "      <td>81136</td>\n",
       "      <td>19</td>\n",
       "      <td>-93</td>\n",
       "      <td>37973</td>\n",
       "      <td>1266</td>\n",
       "      <td>39239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                positive  negative  ...  positiveIncrease  totalTestResultsIncrease\n",
       "state_name                          ...                                            \n",
       "Alabama          10884.0  119473.0  ...              4846                     50440\n",
       "Alaska              79.0   32497.0  ...              -157                     17170\n",
       "American Samoa       0.0     171.0  ...                 0                       171\n",
       "Arizona          12288.0  141132.0  ...              5929                    101005\n",
       "Arkansas          3998.0   77138.0  ...              1266                     39239\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = (df3.loc['2020-05']\n",
    "          .groupby('state_name')\n",
    "          .agg({'positive': 'first',\n",
    "                'negative': 'first',\n",
    "                'pending': 'first',\n",
    "                'recovered': 'first',\n",
    "                'death': 'first',\n",
    "                'hospitalized': 'first', \n",
    "                'total': 'first', \n",
    "                'totalTestResults': 'first',\n",
    "                'deathIncrease': 'sum',\n",
    "                'hospitalizedIncrease': 'sum', \n",
    "                'negativeIncrease': 'sum', \n",
    "                'positiveIncrease': 'sum',\n",
    "                'totalTestResultsIncrease': 'sum'}))\n",
    "\n",
    "df6 = (df3.loc['2020-04']\n",
    "          .groupby('state_name')\n",
    "          .agg({'positive': 'first',\n",
    "                'negative': 'first',\n",
    "                'pending': 'first',\n",
    "                'recovered': 'first',\n",
    "                'death': 'first',\n",
    "                'hospitalized': 'first', \n",
    "                'total': 'first', \n",
    "                'totalTestResults': 'first',\n",
    "                'deathIncrease': 'sum',\n",
    "                'hospitalizedIncrease': 'sum', \n",
    "                'negativeIncrease': 'sum', \n",
    "                'positiveIncrease': 'sum',\n",
    "                'totalTestResultsIncrease': 'sum'}))\n",
    "\n",
    "df7 = df5.sub(df6)\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-wiCGiAf1jJj",
    "outputId": "640f7842-1301-405b-9a37-846bd4774415"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://plotly.com/~ayush.kumar.shah/12/'"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig4 = px.bar(df7, x=df7.index, y='death')\n",
    "fig4.update_layout(xaxis_title='state_name', title='Total Deaths in th US in May only')\n",
    "py.plot(fig4, filename = 'total_deaths_May', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-P9P5fb7BexC"
   },
   "source": [
    "{% include iframe_holder.html url=\"//plotly.com/~ayush.kumar.shah/12.embed\" width=\"900\" height=\"800\" scrolling=\"no\" %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LDcOXxCFU8Zy"
   },
   "source": [
    "<a name=\"problems\"></a>\n",
    "\n",
    "## Problems in the usual coding style\n",
    "\n",
    "Now that I have demonstrated the usual approach followed in pandas notebook, let's discuss the problems in this approach.\n",
    "\n",
    "### 1. Flow is disrupted:\n",
    "\n",
    "The flow of the notebook is very difficult to understand and also creates problems. For example, we may create a variabe name under the plot that needs it. In the above code as well, we created **`df3['active']`** below the cell in which it is needed. So, it may cause errors when run by others. Also, you may have to scroll the notebook for miles and miles.\n",
    "\n",
    "### 2. No reproducibility: \n",
    "\n",
    "When the notebook is shared with others, the other person faces a lot of problems to execute or understand the notebook. For instance, the name of the dataframes doesn't signify any information about the type of dataframe. It runs from **`df1`** to **`df7`** and creates a lot of confusions. But you want to create a notebook whih is very easy to iterate on and the one you can actually share with your colleagues. \n",
    "\n",
    "### 3. Difficult to move the code to production:\n",
    "\n",
    "With this approach, your code is not ready to moved into prodcution. You end up having to rewrite the whole notebook before moving it to production which is obviously not effective.\n",
    "\n",
    "### 4. Unable to automate: \n",
    "\n",
    "The notebook in the current condition cannot be automated for analysis since there may occur a lot of problems like error in code execution, unavailability of filenames used.\n",
    "\n",
    "Although the code may give a interesting conclusion or desired output, we are not quite sure that conclusion is at least correct.\n",
    "\n",
    "Despite having so many problems associated with this approach, it is common for everyone to still use this type of flow while making a notebook since while coding, people enjoy when the code works when they check the outputs and hence keep on continuing the coding in similar way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SDHwE1xr1jJm"
   },
   "source": [
    "<a name=\"solution\"></a>\n",
    "\n",
    "## Coding Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TB9-eR2jGbtK"
   },
   "source": [
    "\n",
    "### 1. Naming convention\n",
    "\n",
    "Follow a naming convention for the notebook according to the task as suggested by [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/#notebooks-are-for-exploration-and-communication) that shows the owner and the order the analysis was done in. You can use the format \n",
    "\n",
    "**`<step>-<ghuser>-<description>.ipynb`**\n",
    "\n",
    "(e.g., **`0.1-ayush-visualize-corona-us.ipynb`**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z_8Fr_t2GZnu"
   },
   "source": [
    "\n",
    "### 2. Plan your steps beforehand\n",
    "\n",
    "Load the data and then think in advanced about all the steps of analysis or tasks you could be doing in the notebook. You don't need to think the logic rightaway but just keep in mind the steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2K808jfsCGMg"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/covid19_us_states_daily.csv', index_col='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bvpYLhA4qKd5"
   },
   "source": [
    "### 3. Create functions\n",
    "\n",
    "You know that initially you want to clean the data and make sure the columns and indexes are in proper usable format. So, why not create a function for that and name it according to the subtasks on the dataframe. \n",
    "\n",
    "> For example, initally you want to make the index a proper datetime object. Then you may want to do ,... , then .... Just add these functions without even thinking the logic and then later you can add the logics. This way, you will be on track and not lost.\n",
    "\n",
    "The functions are created after creating the decorator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLAbhw7WGV43"
   },
   "source": [
    "\n",
    "### 4. Create proper decorators\n",
    "\n",
    "Before adding functions, let's also think about some additional utility that would be helpful. During the pandas analysis, you often check the shape, columns, and other information associated to the dataframe after performing an operation. However, decorator can help automate this process. \n",
    "\n",
    "**`Decorator`** is simply a function that expects a function and returns a function. It's really functional right, haha. Don't get confused by the definition. It is not so difficult as it sounds. We will see how it works in the code below.\n",
    "\n",
    "Also, if you are not familiar with decorators or want to learn more about it, you can visit the [article by Geir Arne Hjelle](https://realpython.com/primer-on-python-decorators/#simple-decorators).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGKomTFhxEpt"
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "def df_info(f):\n",
    "    def wrapper(df, *args, **kwargs):\n",
    "        tic = dt.datetime.now()\n",
    "        result = f(df, *args, **kwargs)\n",
    "        toc = dt.datetime.now()\n",
    "        print(\"\\n\\n{} took {} time\\n\".format(f.__name__, toc - tic))\n",
    "        print(\"After applying {}\\n\".format(f.__name__))\n",
    "        print(\"Shape of df = {}\\n\".format(result.shape))\n",
    "        print(\"Columns of df are {}\\n\".format(result.columns))\n",
    "        print(\"Index of df is {}\\n\".format(result.index))\n",
    "        for i in range(100): print(\"-\", end='')\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSvpEePWwsZk"
   },
   "source": [
    "We have created a decorator called **`df_info`** which displays information like time taken by the function, shape and columns after appling any function **`f`**.\n",
    "\n",
    "The advantage of using deorator is that we get logging. You can modify the decorator according to the information that you want to log or display after applying performing an operation on the dataframe.\n",
    "\n",
    "Now, we create functions as our plan and use these decorators on them by using **`@df_info`**. This will be equivalent to calling **`df_info(f(df, *args, **kwargs))`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84V-SQ-eqnnK"
   },
   "outputs": [],
   "source": [
    "@df_info\n",
    "def create_dateindex(df):\n",
    "    df.index = pd.to_datetime(df.index, format=\"%Y%m%d\")\n",
    "    return df\n",
    "\n",
    "@df_info\n",
    "def remove_columns(df):\n",
    "    df.drop([*df.columns[4:10], *df.columns[11:15], 'posNeg', 'fips'], \n",
    "        axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "@df_info\n",
    "def fill_missing(df):\n",
    "    df.fillna(value=0, inplace=True)\n",
    "    return df\n",
    "\n",
    "@df_info\n",
    "def add_state_name(df):\n",
    "    _df = pd.read_csv('data/state_info.csv', usecols=['state', 'name'])\n",
    "    df = (df\n",
    "      .reset_index()\n",
    "      .merge(_df, on='state', how='left', left_index=True))\n",
    "    df.set_index('date', inplace=True)\n",
    "    df.rename(columns={'name': 'state_name'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "@df_info\n",
    "def drop_state(df):\n",
    "    df.drop(columns=['state'], inplace=True)\n",
    "    return df\n",
    "\n",
    "@df_info\n",
    "def sample_daily(df):\n",
    "    df = df.resample('D').sum()\n",
    "    return df\n",
    "\n",
    "@df_info\n",
    "def add_active_cases(df):\n",
    "    df['active'] = df['positive'] - df['death'] - df['recovered']\n",
    "    return df\n",
    "\n",
    "def aggregate_monthly(df, month):\n",
    "    df = (df.loc[month]\n",
    "        .groupby('state_name')\n",
    "        .agg({'positive': 'first',\n",
    "            'negative': 'first',\n",
    "            'pending': 'first',\n",
    "            'recovered': 'first',\n",
    "            'death': 'first',\n",
    "            'hospitalized': 'first', \n",
    "            'total': 'first', \n",
    "            'totalTestResults': 'first',\n",
    "            'deathIncrease': 'sum',\n",
    "            'hospitalizedIncrease': 'sum', \n",
    "            'negativeIncrease': 'sum', \n",
    "            'positiveIncrease': 'sum',\n",
    "            'totalTestResultsIncrease': 'sum'}))\n",
    "    return df\n",
    "\n",
    "@df_info\n",
    "def create_month_only(df, month):\n",
    "    df_current = aggregate_monthly(df, month)\n",
    "    if int(month[-2:]) == 0:\n",
    "        prev_month = str(int(month[:4]) - 1) + '-12'\n",
    "    else:\n",
    "        prev_month = month[:5] + '{:02d}'.format(int(month[-2:])-1)\n",
    "\n",
    "    df_previous = aggregate_monthly(df, prev_month)\n",
    "    df = df_current.sub(df_previous)\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yT-TjBhQ-lbn"
   },
   "source": [
    "### 5. Remove side effect\n",
    " \n",
    "However, these function make changes which are inplace (side effects) i.e. modifies the original loaded dataframe. So, to solve this, we add a function called start pipeline, which returns a copy of dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "si1ztSdf_qhO"
   },
   "outputs": [],
   "source": [
    "def start_pipeline(df):\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dDswsubX_3Nt"
   },
   "source": [
    "### 6. Constructing pandas pipelines (Main step)\n",
    "\n",
    "Now, let's use this functions to achieve the previous tasks using **`pipe`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "E0POk1L9_2lS",
    "outputId": "2ce36ba6-4698-409c-fe53-87f686d8dd56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "create_dateindex took 0:00:00.003388 time\n",
      "\n",
      "After applying create_dateindex\n",
      "\n",
      "Shape of df = (5113, 34)\n",
      "\n",
      "Columns of df are Index(['state', 'positive', 'negative', 'pending', 'hospitalizedCurrently',\n",
      "       'hospitalizedCumulative', 'inIcuCurrently', 'inIcuCumulative',\n",
      "       'onVentilatorCurrently', 'onVentilatorCumulative', 'recovered',\n",
      "       'dataQualityGrade', 'lastUpdateEt', 'dateModified', 'checkTimeEt',\n",
      "       'death', 'hospitalized', 'dateChecked', 'fips', 'positiveIncrease',\n",
      "       'negativeIncrease', 'total', 'totalTestResults',\n",
      "       'totalTestResultsIncrease', 'posNeg', 'deathIncrease',\n",
      "       'hospitalizedIncrease', 'hash', 'commercialScore',\n",
      "       'negativeRegularScore', 'negativeScore', 'positiveScore', 'score',\n",
      "       'grade'],\n",
      "      dtype='object')\n",
      "\n",
      "Index of df is DatetimeIndex(['2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04',\n",
      "               ...\n",
      "               '2020-01-31', '2020-01-30', '2020-01-29', '2020-01-28',\n",
      "               '2020-01-27', '2020-01-26', '2020-01-25', '2020-01-24',\n",
      "               '2020-01-23', '2020-01-22'],\n",
      "              dtype='datetime64[ns]', name='date', length=5113, freq=None)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "remove_columns took 0:00:00.002087 time\n",
      "\n",
      "After applying remove_columns\n",
      "\n",
      "Shape of df = (5113, 22)\n",
      "\n",
      "Columns of df are Index(['state', 'positive', 'negative', 'pending', 'recovered', 'death',\n",
      "       'hospitalized', 'dateChecked', 'positiveIncrease', 'negativeIncrease',\n",
      "       'total', 'totalTestResults', 'totalTestResultsIncrease',\n",
      "       'deathIncrease', 'hospitalizedIncrease', 'hash', 'commercialScore',\n",
      "       'negativeRegularScore', 'negativeScore', 'positiveScore', 'score',\n",
      "       'grade'],\n",
      "      dtype='object')\n",
      "\n",
      "Index of df is DatetimeIndex(['2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04',\n",
      "               ...\n",
      "               '2020-01-31', '2020-01-30', '2020-01-29', '2020-01-28',\n",
      "               '2020-01-27', '2020-01-26', '2020-01-25', '2020-01-24',\n",
      "               '2020-01-23', '2020-01-22'],\n",
      "              dtype='datetime64[ns]', name='date', length=5113, freq=None)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "fill_missing took 0:00:00.006381 time\n",
      "\n",
      "After applying fill_missing\n",
      "\n",
      "Shape of df = (5113, 22)\n",
      "\n",
      "Columns of df are Index(['state', 'positive', 'negative', 'pending', 'recovered', 'death',\n",
      "       'hospitalized', 'dateChecked', 'positiveIncrease', 'negativeIncrease',\n",
      "       'total', 'totalTestResults', 'totalTestResultsIncrease',\n",
      "       'deathIncrease', 'hospitalizedIncrease', 'hash', 'commercialScore',\n",
      "       'negativeRegularScore', 'negativeScore', 'positiveScore', 'score',\n",
      "       'grade'],\n",
      "      dtype='object')\n",
      "\n",
      "Index of df is DatetimeIndex(['2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04',\n",
      "               ...\n",
      "               '2020-01-31', '2020-01-30', '2020-01-29', '2020-01-28',\n",
      "               '2020-01-27', '2020-01-26', '2020-01-25', '2020-01-24',\n",
      "               '2020-01-23', '2020-01-22'],\n",
      "              dtype='datetime64[ns]', name='date', length=5113, freq=None)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "add_state_name took 0:00:00.015122 time\n",
      "\n",
      "After applying add_state_name\n",
      "\n",
      "Shape of df = (5113, 23)\n",
      "\n",
      "Columns of df are Index(['state', 'positive', 'negative', 'pending', 'recovered', 'death',\n",
      "       'hospitalized', 'dateChecked', 'positiveIncrease', 'negativeIncrease',\n",
      "       'total', 'totalTestResults', 'totalTestResultsIncrease',\n",
      "       'deathIncrease', 'hospitalizedIncrease', 'hash', 'commercialScore',\n",
      "       'negativeRegularScore', 'negativeScore', 'positiveScore', 'score',\n",
      "       'grade', 'state_name'],\n",
      "      dtype='object')\n",
      "\n",
      "Index of df is DatetimeIndex(['2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04',\n",
      "               ...\n",
      "               '2020-01-31', '2020-01-30', '2020-01-29', '2020-01-28',\n",
      "               '2020-01-27', '2020-01-26', '2020-01-25', '2020-01-24',\n",
      "               '2020-01-23', '2020-01-22'],\n",
      "              dtype='datetime64[ns]', name='date', length=5113, freq=None)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "sample_daily took 0:00:00.017170 time\n",
      "\n",
      "After applying sample_daily\n",
      "\n",
      "Shape of df = (135, 19)\n",
      "\n",
      "Columns of df are Index(['positive', 'negative', 'pending', 'recovered', 'death', 'hospitalized',\n",
      "       'positiveIncrease', 'negativeIncrease', 'total', 'totalTestResults',\n",
      "       'totalTestResultsIncrease', 'deathIncrease', 'hospitalizedIncrease',\n",
      "       'commercialScore', 'negativeRegularScore', 'negativeScore',\n",
      "       'positiveScore', 'score', 'grade'],\n",
      "      dtype='object')\n",
      "\n",
      "Index of df is DatetimeIndex(['2020-01-22', '2020-01-23', '2020-01-24', '2020-01-25',\n",
      "               '2020-01-26', '2020-01-27', '2020-01-28', '2020-01-29',\n",
      "               '2020-01-30', '2020-01-31',\n",
      "               ...\n",
      "               '2020-05-26', '2020-05-27', '2020-05-28', '2020-05-29',\n",
      "               '2020-05-30', '2020-05-31', '2020-06-01', '2020-06-02',\n",
      "               '2020-06-03', '2020-06-04'],\n",
      "              dtype='datetime64[ns]', name='date', length=135, freq='D')\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "add_active_cases took 0:00:00.002020 time\n",
      "\n",
      "After applying add_active_cases\n",
      "\n",
      "Shape of df = (135, 20)\n",
      "\n",
      "Columns of df are Index(['positive', 'negative', 'pending', 'recovered', 'death', 'hospitalized',\n",
      "       'positiveIncrease', 'negativeIncrease', 'total', 'totalTestResults',\n",
      "       'totalTestResultsIncrease', 'deathIncrease', 'hospitalizedIncrease',\n",
      "       'commercialScore', 'negativeRegularScore', 'negativeScore',\n",
      "       'positiveScore', 'score', 'grade', 'active'],\n",
      "      dtype='object')\n",
      "\n",
      "Index of df is DatetimeIndex(['2020-01-22', '2020-01-23', '2020-01-24', '2020-01-25',\n",
      "               '2020-01-26', '2020-01-27', '2020-01-28', '2020-01-29',\n",
      "               '2020-01-30', '2020-01-31',\n",
      "               ...\n",
      "               '2020-05-26', '2020-05-27', '2020-05-28', '2020-05-29',\n",
      "               '2020-05-30', '2020-05-31', '2020-06-01', '2020-06-02',\n",
      "               '2020-06-03', '2020-06-04'],\n",
      "              dtype='datetime64[ns]', name='date', length=135, freq='D')\n",
      "\n",
      "----------------------------------------------------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "df_daily = (df.pipe(start_pipeline)\n",
    "            .pipe(create_dateindex)\n",
    "            .pipe(remove_columns)\n",
    "            .pipe(fill_missing)\n",
    "            .pipe(add_state_name)\n",
    "            .pipe(sample_daily)\n",
    "            .pipe(add_active_cases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yek6eDhKzgVZ",
    "outputId": "eafe5131-675d-489a-e185-6b104ae47c3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://plotly.com/~ayush.kumar.shah/4/'"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig2 = px.line(df_daily, x=df_daily.index, y='death')\n",
    "fig2.update_layout(xaxis_title='date', title='Total deaths in the U.S. (Cumulative)')\n",
    "py.plot(fig2, filename = 'total_daily_deaths', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7RYNRxJBtqS"
   },
   "source": [
    "{% include iframe_holder.html url=\"//plotly.com/~ayush.kumar.shah/4.embed\" width=\"900\" height=\"800\" scrolling=\"no\" %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1zz9ieamzHfc",
    "outputId": "081f45aa-3211-4b3c-89a2-e248a38aef51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://plotly.com/~ayush.kumar.shah/6/'"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig3 = px.line(df_daily, x=df_daily.index, y='active')\n",
    "fig3.update_layout(xaxis_title='date', title='Total active cases in the U.S. (Cumulative)')\n",
    "py.plot(fig3, filename = 'total_daily_active', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v0FBjNcwBw_A"
   },
   "source": [
    "{% include iframe_holder.html url=\"//plotly.com/~ayush.kumar.shah/6.embed\" width=\"900\" height=\"800\" scrolling=\"no\" %}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0PKOHeDkHO6B",
    "outputId": "242fb9ac-fdad-4185-9906-3e7f3ff12e54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "create_dateindex took 0:00:00.002492 time\n",
      "\n",
      "After applying create_dateindex\n",
      "\n",
      "Shape of df = (5113, 34)\n",
      "\n",
      "Columns of df are Index(['state', 'positive', 'negative', 'pending', 'hospitalizedCurrently',\n",
      "       'hospitalizedCumulative', 'inIcuCurrently', 'inIcuCumulative',\n",
      "       'onVentilatorCurrently', 'onVentilatorCumulative', 'recovered',\n",
      "       'dataQualityGrade', 'lastUpdateEt', 'dateModified', 'checkTimeEt',\n",
      "       'death', 'hospitalized', 'dateChecked', 'fips', 'positiveIncrease',\n",
      "       'negativeIncrease', 'total', 'totalTestResults',\n",
      "       'totalTestResultsIncrease', 'posNeg', 'deathIncrease',\n",
      "       'hospitalizedIncrease', 'hash', 'commercialScore',\n",
      "       'negativeRegularScore', 'negativeScore', 'positiveScore', 'score',\n",
      "       'grade'],\n",
      "      dtype='object')\n",
      "\n",
      "Index of df is DatetimeIndex(['2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04',\n",
      "               ...\n",
      "               '2020-01-31', '2020-01-30', '2020-01-29', '2020-01-28',\n",
      "               '2020-01-27', '2020-01-26', '2020-01-25', '2020-01-24',\n",
      "               '2020-01-23', '2020-01-22'],\n",
      "              dtype='datetime64[ns]', name='date', length=5113, freq=None)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "remove_columns took 0:00:00.002219 time\n",
      "\n",
      "After applying remove_columns\n",
      "\n",
      "Shape of df = (5113, 22)\n",
      "\n",
      "Columns of df are Index(['state', 'positive', 'negative', 'pending', 'recovered', 'death',\n",
      "       'hospitalized', 'dateChecked', 'positiveIncrease', 'negativeIncrease',\n",
      "       'total', 'totalTestResults', 'totalTestResultsIncrease',\n",
      "       'deathIncrease', 'hospitalizedIncrease', 'hash', 'commercialScore',\n",
      "       'negativeRegularScore', 'negativeScore', 'positiveScore', 'score',\n",
      "       'grade'],\n",
      "      dtype='object')\n",
      "\n",
      "Index of df is DatetimeIndex(['2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04',\n",
      "               ...\n",
      "               '2020-01-31', '2020-01-30', '2020-01-29', '2020-01-28',\n",
      "               '2020-01-27', '2020-01-26', '2020-01-25', '2020-01-24',\n",
      "               '2020-01-23', '2020-01-22'],\n",
      "              dtype='datetime64[ns]', name='date', length=5113, freq=None)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "fill_missing took 0:00:00.001883 time\n",
      "\n",
      "After applying fill_missing\n",
      "\n",
      "Shape of df = (5113, 22)\n",
      "\n",
      "Columns of df are Index(['state', 'positive', 'negative', 'pending', 'recovered', 'death',\n",
      "       'hospitalized', 'dateChecked', 'positiveIncrease', 'negativeIncrease',\n",
      "       'total', 'totalTestResults', 'totalTestResultsIncrease',\n",
      "       'deathIncrease', 'hospitalizedIncrease', 'hash', 'commercialScore',\n",
      "       'negativeRegularScore', 'negativeScore', 'positiveScore', 'score',\n",
      "       'grade'],\n",
      "      dtype='object')\n",
      "\n",
      "Index of df is DatetimeIndex(['2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04',\n",
      "               ...\n",
      "               '2020-01-31', '2020-01-30', '2020-01-29', '2020-01-28',\n",
      "               '2020-01-27', '2020-01-26', '2020-01-25', '2020-01-24',\n",
      "               '2020-01-23', '2020-01-22'],\n",
      "              dtype='datetime64[ns]', name='date', length=5113, freq=None)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "add_state_name took 0:00:00.014981 time\n",
      "\n",
      "After applying add_state_name\n",
      "\n",
      "Shape of df = (5113, 23)\n",
      "\n",
      "Columns of df are Index(['state', 'positive', 'negative', 'pending', 'recovered', 'death',\n",
      "       'hospitalized', 'dateChecked', 'positiveIncrease', 'negativeIncrease',\n",
      "       'total', 'totalTestResults', 'totalTestResultsIncrease',\n",
      "       'deathIncrease', 'hospitalizedIncrease', 'hash', 'commercialScore',\n",
      "       'negativeRegularScore', 'negativeScore', 'positiveScore', 'score',\n",
      "       'grade', 'state_name'],\n",
      "      dtype='object')\n",
      "\n",
      "Index of df is DatetimeIndex(['2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04',\n",
      "               '2020-06-04', '2020-06-04',\n",
      "               ...\n",
      "               '2020-01-31', '2020-01-30', '2020-01-29', '2020-01-28',\n",
      "               '2020-01-27', '2020-01-26', '2020-01-25', '2020-01-24',\n",
      "               '2020-01-23', '2020-01-22'],\n",
      "              dtype='datetime64[ns]', name='date', length=5113, freq=None)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "create_month_only took 0:00:00.031071 time\n",
      "\n",
      "After applying create_month_only\n",
      "\n",
      "Shape of df = (56, 13)\n",
      "\n",
      "Columns of df are Index(['positive', 'negative', 'pending', 'recovered', 'death', 'hospitalized',\n",
      "       'total', 'totalTestResults', 'deathIncrease', 'hospitalizedIncrease',\n",
      "       'negativeIncrease', 'positiveIncrease', 'totalTestResultsIncrease'],\n",
      "      dtype='object')\n",
      "\n",
      "Index of df is Index(['Alabama', 'Alaska', 'American Samoa', 'Arizona', 'Arkansas',\n",
      "       'California', 'Colorado', 'Connecticut', 'Delaware',\n",
      "       'District Of Columbia', 'Florida', 'Georgia', 'Guam', 'Hawaii', 'Idaho',\n",
      "       'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana',\n",
      "       'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
      "       'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
      "       'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
      "       'North Carolina', 'North Dakota', 'Northern Mariana Islands', 'Ohio',\n",
      "       'Oklahoma', 'Oregon', 'Pennsylvania', 'Puerto Rico', 'Rhode Island',\n",
      "       'South Carolina', 'South Dakota', 'Tennessee', 'Texas',\n",
      "       'US Virgin Islands', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
      "       'West Virginia', 'Wisconsin', 'Wyoming'],\n",
      "      dtype='object', name='state_name')\n",
      "\n",
      "----------------------------------------------------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "df_may = create_month_only(\n",
    "                df=(df.pipe(start_pipeline)\n",
    "                    .pipe(create_dateindex)\n",
    "                    .pipe(remove_columns)\n",
    "                    .pipe(fill_missing)\n",
    "                    .pipe(add_state_name)), \n",
    "                month='2020-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7vRRbfQPzm_w",
    "outputId": "1a96d29c-ed32-4522-9d0d-fc1304b81c62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://plotly.com/~ayush.kumar.shah/12/'"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig4 = px.bar(df_may, x=df_may.index, y='death')\n",
    "fig4.update_layout(xaxis_title='state_name', title='Total Deaths in th US in May only')\n",
    "py.plot(fig4, filename = 'total_deaths_May', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hgh8f2bVLEfO"
   },
   "source": [
    "{% include iframe_holder.html url=\"//plotly.com/~ayush.kumar.shah/12.embed\" width=\"900\" height=\"800\" scrolling=\"no\" %}\n",
    "\n",
    "You can observe how easily pipe functionality has achieved the required task in a clean and organized way. Also, the original dataframe is intact and not affected by the above operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "m1vP0YXILA-0",
    "outputId": "3b9baa8c-2574-4a21-d203-a5120a47efc6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>pending</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "      <th>hospitalizedCumulative</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "      <th>inIcuCumulative</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "      <th>onVentilatorCumulative</th>\n",
       "      <th>recovered</th>\n",
       "      <th>dataQualityGrade</th>\n",
       "      <th>lastUpdateEt</th>\n",
       "      <th>dateModified</th>\n",
       "      <th>checkTimeEt</th>\n",
       "      <th>death</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>dateChecked</th>\n",
       "      <th>fips</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>posNeg</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>hash</th>\n",
       "      <th>commercialScore</th>\n",
       "      <th>negativeRegularScore</th>\n",
       "      <th>negativeScore</th>\n",
       "      <th>positiveScore</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20200604</th>\n",
       "      <td>AK</td>\n",
       "      <td>513.0</td>\n",
       "      <td>59584.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>376.0</td>\n",
       "      <td>A</td>\n",
       "      <td>6/4/2020 00:00</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>06/03 20:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1907</td>\n",
       "      <td>60097</td>\n",
       "      <td>60097</td>\n",
       "      <td>1915</td>\n",
       "      <td>60097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c1046011af7271cbe2e6698526714c6cb5b92748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200604</th>\n",
       "      <td>AL</td>\n",
       "      <td>19072.0</td>\n",
       "      <td>216227.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>601.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.0</td>\n",
       "      <td>11395.0</td>\n",
       "      <td>B</td>\n",
       "      <td>6/4/2020 00:00</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>06/03 20:00</td>\n",
       "      <td>653.0</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>3484</td>\n",
       "      <td>235299</td>\n",
       "      <td>235299</td>\n",
       "      <td>3705</td>\n",
       "      <td>235299</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>bcbefdb36212ba2b97b5a354f4e45bf16648ee23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200604</th>\n",
       "      <td>AR</td>\n",
       "      <td>8067.0</td>\n",
       "      <td>134413.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>5717.0</td>\n",
       "      <td>A</td>\n",
       "      <td>6/4/2020 00:00</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>06/03 20:00</td>\n",
       "      <td>142.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142480</td>\n",
       "      <td>142480</td>\n",
       "      <td>0</td>\n",
       "      <td>142480</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>acd3a4fbbc3dbb32138725f91e3261d683e7052a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200604</th>\n",
       "      <td>AS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>6/1/2020 00:00</td>\n",
       "      <td>2020-06-01T00:00:00Z</td>\n",
       "      <td>05/31 20:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-01T00:00:00Z</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8bbc72fa42781e0549e2e4f9f4c3e7cbef14ab32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200604</th>\n",
       "      <td>AZ</td>\n",
       "      <td>22753.0</td>\n",
       "      <td>227002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5172.0</td>\n",
       "      <td>A+</td>\n",
       "      <td>6/4/2020 00:00</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>06/03 20:00</td>\n",
       "      <td>996.0</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>2020-06-04T00:00:00Z</td>\n",
       "      <td>4</td>\n",
       "      <td>520</td>\n",
       "      <td>4710</td>\n",
       "      <td>249755</td>\n",
       "      <td>249755</td>\n",
       "      <td>5230</td>\n",
       "      <td>249755</td>\n",
       "      <td>15</td>\n",
       "      <td>66</td>\n",
       "      <td>1fa237b8204cd23701577aef6338d339daa4452e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         state  positive  negative  ...  positiveScore  score  grade\n",
       "date                                ...                             \n",
       "20200604    AK     513.0   59584.0  ...              0      0    NaN\n",
       "20200604    AL   19072.0  216227.0  ...              0      0    NaN\n",
       "20200604    AR    8067.0  134413.0  ...              0      0    NaN\n",
       "20200604    AS       0.0     174.0  ...              0      0    NaN\n",
       "20200604    AZ   22753.0  227002.0  ...              0      0    NaN\n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qoiqypn2GYlJ"
   },
   "source": [
    "\n",
    "### 7. Create a module\n",
    "\n",
    "Finally, you can create a module (eg `processing.py`) and keep all the above functions in the module. You can simply import them here and use it directly. It will clean the notebook further. \n",
    "\n",
    "**`processing.py`**\n",
    "\n",
    "<script src=\"https://gist.github.com/ayushkumarshah/aa35d7fbfb9474d2a615665766d20a35.js\"></script>\n",
    "\n",
    "While loading the modules, load the \"autoreload\" extension so that you can change code in the modules and the changes get updated automatically. For more info, see [autoreload documentation](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "o82WVkC0I4id",
    "outputId": "03b10b77-c457-48aa-a1a8-b84d97b45683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CU7VA5C8_oyn"
   },
   "source": [
    "<a name=\"advantages\"></a>\n",
    "\n",
    "## Advantages\n",
    "\n",
    "### 1. Effective for long run (Maintainability)\n",
    "\n",
    "Although, the approach may look like an inefficient method of coding but it is very effective for the long run since you will not have to spend hours maintaining the notebook. Given the functions are well written and well defined, they are ready for production.\n",
    "\n",
    "The code is easily sharable as well as anyone can understand the code unlike in the previous appraoch. Also, for complex analysis tasks, this approach can be esaily used for maintaining the notebook.\n",
    "\n",
    "### 2. Proper flow and planning\n",
    "\n",
    "You do not need to think about logic of the analysis at the beginning. You can just plan your tasks and write down the required functions which already gives you kind of a framework of mind which helps to be on track. The calm that will follow is likely going to have a greater impact in innovation. \n",
    "\n",
    "Then, you can finally define the logic at the end to make it actually work.  \n",
    "\n",
    "### 3. Easier to modify\n",
    "\n",
    "You might have noticed that the `pipe` functionality gives you the ability to modify the tasks or flow easily. You can do so by commenting or adding the functions in the pipeline.\n",
    "\n",
    "For example, you don't want to remove the columns and sample the data daily. Then you can achieve this simply by commenting those lines as shown below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93e1R01nK6is"
   },
   "outputs": [],
   "source": [
    "df_daily = (df.pipe(start_pipeline)\n",
    "            .pipe(create_dateindex)\n",
    "            # .pipe(remove_columns)\n",
    "            .pipe(fill_missing)\n",
    "            .pipe(add_state_name)\n",
    "            .pipe(drop_state)\n",
    "            # .pipe(sample_daily)\n",
    "            .pipe(add_active_cases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hr8j67f6K5dW"
   },
   "source": [
    "### 4. Easier to debug\n",
    "\n",
    "In this approach, you know what is actually happening in each step which makes it a lot easier to debug. Furthermore, since all the operations are functions, you can easily debug the code by performing unit tests or using other methods on the functions. \n",
    "\n",
    "### 5. Readability\n",
    "\n",
    "This approach helps you prevent miles of scrolling and also is easily readable than the previous approach. By lloking at the code, you can easily understand what operations are being performed on the data and also can see the effect of those operations on the data in each step using decorator.\n",
    "\n",
    "Example:\n",
    "\n",
    "Let us consider cooking chicken. When we do so, we don't describe the steps like this:\n",
    "\n",
    "```\n",
    "temperature = 210 celsius\n",
    "food1 = Chicken\n",
    "food2 = Season(food1, with Spices)\n",
    "food3 = Season(food2, with Gravy)\n",
    "Serve(PutInOven(food3, temperature), on a plate)\n",
    "```\n",
    "\n",
    "But instead, we describe it the following way:\n",
    "\n",
    "```\n",
    "temperature = 210 celsius\n",
    "Chicken.Season(with Spices)\n",
    "        .Season(with Gravy)\n",
    "        .PutInOven(temperature)\n",
    "        .Serve()\n",
    "```\n",
    "\n",
    "The pipe functionality helps us to write code in the latter way, which is alos much more readable.\n",
    "\n",
    "### 6. Reusability\n",
    "\n",
    "During production, we turn the project into a Python package. You can import your code and use it in notebooks with a cell. You do not need to write code to do the same task in multiple notebooks. \n",
    "\n",
    "### 7. Separation into analysis and data manipulation\n",
    "\n",
    "Once your functions have been moved to a separate module, two levels of abstraction is obtained: analysis and data manipulation. \n",
    "\n",
    "You can fiddle around on a high level and keep the details on a low level. The notebook\n",
    "then becomes the summary and a user interface where you can very quickly make nice little charts instead of manipulating data or performing analytical steps to get a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWoa5hlN7W6A"
   },
   "source": [
    "# Final notes\n",
    "\n",
    "Hence, following these practices while coding in pandas or performing other similar tasks like building scikin-learn pipelines or other ML pipelnes, can be extremely beneficial for developers. Also, all the 4 problems mentioned in the beginning has been solved in this approach. Thus, giving utmost priority to clarity and interoperability, we should remember that it's a lot easier to solve a problem if we understand the problem well. \n",
    "\n",
    "Moreover, if you find writing these codes difficult, Vincent and his team has developed  a package called [Scikit-lego](https://scikit-lego.readthedocs.io/en/latest/pandas_pipeline.html#) which does all this for you with additional features like custom logging. Do check it out.\n",
    "\n",
    "Also, if you have any confusions or sugestions, feel free to comment. I am all ears. Thank you.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2020-06-05-pandas-pipe-plotly.ipynb",
   "provenance": []
  },
  "jekyll": {
   "permalink": "/:year/:month/:title/",
   "title": "Pandas efficient coding"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
